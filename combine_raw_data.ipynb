{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_gov_danf(df):\n",
    "    return df.loc[0, 2]\n",
    "\n",
    "def fix_emitente(df):\n",
    "    return pd.DataFrame( \n",
    "                        df.loc[:, 1]    # Select data\n",
    "                        .str.split(\"|\") # Split IE\n",
    "                        .explode()      # Explode IE into rows\n",
    "                        .str.split(\":\") # Split key and value\n",
    "                        .to_list()      # Convert to list\n",
    "                        , columns=[\"key\", \"value\"]) # Create columns and convert to pandas dataframe\n",
    "\n",
    "def fix_destinatario(df):\n",
    "    return pd.DataFrame(df.loc[:, 1]\n",
    "                        .str.split(\":\", n=1)\n",
    "                        .to_list()\n",
    "                        , columns=[\"key\", \"value\"]\n",
    "                        )\n",
    "    \n",
    "def fix_items(df):\n",
    "    df.columns = df.iloc[0]\n",
    "    df.drop(0, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.drop(df.columns[:2], axis=1, inplace=True)\n",
    "    return df\n",
    "    \n",
    "def fix_total(df):\n",
    "    df.drop(0, axis=1, inplace=True)\n",
    "    df.columns = [\"key\", \"value\"]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "def add_id(df, cont):\n",
    "    df[\"id_file\"] = cont\n",
    "    return df[[\"id_file\"] + df.columns[:-1].tolist()]\n",
    "\n",
    "def fix_footer(df):\n",
    "    temp_df = df.split(\"||\")\n",
    "    temp_df = pd.Series(temp_df).str.split(\":\", n=1, expand=True)\n",
    "    temp_df.columns = [\"key\", \"value\"]\n",
    "    return temp_df\n",
    "\n",
    "def fix_column_upper(df):\n",
    "    \"\"\"Remove accents and apply lower case on columns names, apply upper and strip to values in columns\n",
    "\n",
    "    Args:\n",
    "        df (pd.Dataframe): A dataframe with columns names and values\n",
    "    \"\"\"\n",
    "    df.columns = ([ unidecode(ii)\n",
    "                   .lower()\n",
    "                   .replace(\" \", \"_\")\n",
    "                   .replace(\".\", \"\")\n",
    "                   for ii in df.columns])\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col == \"key\":\n",
    "                df[col] = ( df[col]\n",
    "                    .apply(lambda x: unidecode(x)\n",
    "                           .replace(\"(R$)\", \"\")\n",
    "                           .replace(\"NFC-e\", \"\")\n",
    "                           .replace(\"NF-e\", \"\")\n",
    "                           .strip()\n",
    "                           .lower()\n",
    "                           .replace(\" \", \"_\")\n",
    "                           )\n",
    "                    )    \n",
    "        else:\n",
    "            df[col] = ( df[col].apply(lambda x: str(x))\n",
    "                    .str.upper()\n",
    "                    .str.strip()\n",
    "                    )\n",
    "            \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_path = \"Raw_Data/Raw_DFs/\"\n",
    "url_path = \"Raw_Data/\"\n",
    "\n",
    "url_test = \"urls\" \n",
    "url_df = pd.read_csv(f\"{url_path}{url_test}.csv\").fillna(\"Failed\")\n",
    "\n",
    "mask = url_df.df_id == \"Failed\"\n",
    "url_df = url_df[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicated rows based in columns df_id\n",
    "url_df.drop_duplicates(subset=\"df_id\", inplace=True)\n",
    "url_df.reset_index(drop=True, inplace=True)\n",
    "# Update file\n",
    "# url_df.to_csv(f\"{url_path}{url_test}.csv\", index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of files in url.csv: 810\n",
      "Total of files in folder: 810\n"
     ]
    }
   ],
   "source": [
    "# Files List\n",
    "files_list = os.listdir(dfs_path)\n",
    "files_dict = {}\n",
    "\n",
    "for file_path in files_list:\n",
    "    # Create a dict with the name of file as key and the suffix of subfiles as a list\n",
    "    if \".csv\" in file_path:\n",
    "        key, value = file_path.replace(\".csv\", \"\").rsplit(\"_\", 1)\n",
    "        if key in files_dict:\n",
    "            concat_val = files_dict[key] + [value]\n",
    "            files_dict[key] = concat_val\n",
    "        else:\n",
    "            files_dict[key] = [value]\n",
    "            \n",
    "# Show the total of files in url.csv and compare with the number of files in the folder\n",
    "print(f\"Total of files in url.csv: {url_df.shape[0]}\\nTotal of files in folder: {len(files_dict.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dfs to store the data\n",
    "df_gov = pd.DataFrame(columns = [\"id_file\", \"gov\", \"danfe\", \"url\"])\n",
    "df_emitente = pd.DataFrame(columns = [\"id_file\", \"key\", \"value\"])\n",
    "df_destinatario = pd.DataFrame(columns = [\"id_file\", \"key\", \"value\"])\n",
    "df_items = pd.DataFrame(columns = [\"id_file\", \"Item\", \"Descrição\", \"Qtde.\", \"Unid.\", \"Vl. unid.\", \"Vl. total\"])\n",
    "df_pagamento = pd.DataFrame(columns = [\"id_file\", \"key\", \"value\"])\n",
    "df_nfe_info = pd.DataFrame(columns=[\"id_file\", \"key\", \"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 810/810 [00:29<00:00, 27.01it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for idx, (file_name, sub_files) in tqdm(enumerate(files_dict.items()), total=len(files_dict.items())):\n",
    "      # Read all files\n",
    "      sub_files = map(int, sub_files)\n",
    "      df_list_raw = [pd.read_csv(f\"{dfs_path}{file_name}_{item}.csv\", header = None) for item in sub_files]\n",
    "      \n",
    "      # Retrieve url\n",
    "      mask = url_df.df_id == file_name\n",
    "      file_url = url_df.loc[mask, \"url\"].values[0]\n",
    "      # Store data\n",
    "      df_gov.loc[len(df_gov)]       = [file_name, fix_gov_danf(df_list_raw[0]), fix_gov_danf(df_list_raw[1]), file_url]\n",
    "      df_emitente                   = pd.concat([df_emitente, add_id(fix_emitente(df_list_raw[2]), file_name)])\n",
    "      df_destinatario               = pd.concat([df_destinatario, add_id(fix_destinatario(df_list_raw[3]), file_name)])\n",
    "      df_items                      = pd.concat([df_items, add_id(fix_items(df_list_raw[4]), file_name)])\n",
    "      df_pagamento                  = pd.concat([df_pagamento, add_id(fix_total(df_list_raw[5]), file_name)])\n",
    "      df_nfe_info                   = pd.concat([df_nfe_info, add_id(fix_footer(url_df.loc[idx, \"footer\"]), file_name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_emitende = df_emitente.copy()\n",
    "temp_destinatario = df_destinatario.copy()\n",
    "temp_items = df_items.copy()\n",
    "temp_pagamento = df_pagamento.copy()\n",
    "temp_nfe = df_nfe_info.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emitente = temp_emitende.copy()\n",
    "df_destinatario = temp_destinatario.copy()\n",
    "df_items = temp_items.copy()\n",
    "df_pagamento = temp_pagamento.copy()\n",
    "df_nfe_info = temp_nfe.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize columns upper case values in columns, lower case in columns names and remove accents\n",
    "fix_column_upper(df_emitente)\n",
    "fix_column_upper(df_destinatario)\n",
    "fix_column_upper(df_items)\n",
    "fix_column_upper(df_pagamento)\n",
    "fix_column_upper(df_nfe_info)\n",
    "\n",
    "# Reindex\n",
    "df_emitente.reset_index(drop=True, inplace=True)\n",
    "df_destinatario.reset_index(drop=True, inplace=True)\n",
    "df_items.reset_index(drop=True, inplace=True)\n",
    "df_pagamento.reset_index(drop=True, inplace=True)\n",
    "df_nfe_info.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Remove unecessary rows\n",
    "mask = df_emitente.key == \"emitente\"\n",
    "df_emitente = df_emitente[~mask]\n",
    "\n",
    "mask = df_nfe_info.key == \"sem_valor_fiscal\"\n",
    "df_nfe_info = df_nfe_info[~mask]\n",
    "\n",
    "# Move the value of chave_de_acesso from column key to column value ( correct place )\n",
    "mask = df_nfe_info.key.str.contains(\"chave\")\n",
    "target_index = df_nfe_info[mask].index.to_list()\n",
    "for idx in target_index:\n",
    "    df_nfe_info.loc[idx, \"value\"] = df_nfe_info.loc[idx+1, \"key\"]\n",
    "    \n",
    "# Remove the moved ( duplicated ) row\n",
    "mask2 = df_nfe_info.key.isin(df_nfe_info[mask].value)\n",
    "df_nfe_info = df_nfe_info[~mask2]\n",
    "\n",
    "# Convert long to wide\n",
    "df_emitente = df_emitente.pivot(index=\"id_file\", columns=\"key\", values=\"value\").reset_index()\n",
    "df_destinatario = df_destinatario.pivot(index=\"id_file\", columns=\"key\", values=\"value\").reset_index()\n",
    "df_pagamento = df_pagamento.pivot(index=\"id_file\", columns=\"key\", values=\"value\").reset_index()\n",
    "df_nfe_info = df_nfe_info.pivot(index=\"id_file\", columns=\"key\", values=\"value\").reset_index()\n",
    "\n",
    "# Rename columns\n",
    "df_emitente.rename(columns={\"endereco\": \"endereco_emitente\"}, inplace=True)\n",
    "df_destinatario.rename(columns={\"endereco\": \"endereco_destinatario\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix type\n",
    "df_items[[\"qtde\", \"vl_unid\", \"vl_total\"]] = df_items[[\"qtde\", \"vl_unid\", \"vl_total\"]].astype(float)\n",
    "df_pagamento[[\"valor_descontos\", \"valor_pago\", \"valor_total\", \"valor_total_dos_produtos\"]] = df_pagamento[[\"valor_descontos\", \"valor_pago\", \"valor_total\", \"valor_total_dos_produtos\"]].astype(float)\n",
    "\n",
    "df_nfe_info[\"data_de_autorizacao\"] = pd.to_datetime(df_nfe_info[\"data_de_autorizacao\"], format=\"%d/%m/%Y %H:%M:%S\")\n",
    "df_nfe_info[\"data_de_cancelamento\"] = pd.to_datetime(df_nfe_info[\"data_de_cancelamento\"], format=\"%d/%m/%Y %H:%M:%S\")\n",
    "df_nfe_info[\"data_de_emissao\"] = pd.to_datetime(df_nfe_info[\"data_de_emissao\"], format=\"%d/%m/%Y %H:%M:%S\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emitente.nome_fantasia.fillna(df_emitente.razao_social, inplace=True)\n",
    "df_emitente.razao_social.fillna(df_emitente.nome_fantasia, inplace=True)\n",
    "# Fix user names\n",
    "mask = df_destinatario.endereco_destinatario.str.contains(\"caico\", case=False, na=False)\n",
    "df_destinatario.loc[mask, \"nome\"] = \"IVANILSON ( CAICÓ )\"\n",
    "df_destinatario.loc[mask, \"cpf\"] = \"503.185.514-20\"\n",
    "\n",
    "df_destinatario.cpf.fillna(\"000.000.000-00\", inplace=True)\n",
    "df_destinatario.endereco_destinatario.fillna(\"Sem Info.\", inplace=True)\n",
    "df_destinatario.nome.fillna(\"Sem Info.\", inplace=True)\n",
    "\n",
    "df_pagamento.forma_pagamento.fillna(\"Sem Info.\", inplace=True)\n",
    "df_pagamento.icms.fillna(0, inplace=True)\n",
    "df_pagamento.valor_total.fillna(df_pagamento.valor_total_dos_produtos, inplace=True)\n",
    "df_pagamento.valor_total_dos_produtos.fillna(df_pagamento.valor_total, inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nfe = pd.concat([df_gov.set_index(\"id_file\"), df_emitente.set_index(\"id_file\"), df_destinatario.set_index(\"id_file\"), \n",
    "     df_pagamento.set_index(\"id_file\"), df_nfe_info.set_index(\"id_file\")], axis=1, join=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gov                            0\n",
       "danfe                          0\n",
       "url                            0\n",
       "cnpj                           0\n",
       "endereco_emitente              0\n",
       "ie                             0\n",
       "nome_fantasia                  0\n",
       "razao_social                   0\n",
       "cpf                            0\n",
       "destinatario                   0\n",
       "endereco_destinatario          0\n",
       "nome                           0\n",
       "forma_pagamento                0\n",
       "icms                           0\n",
       "valor_descontos                0\n",
       "valor_pago                     0\n",
       "valor_total                    0\n",
       "valor_total_dos_produtos       0\n",
       "chave_de_acesso                0\n",
       "data_de_autorizacao            0\n",
       "data_de_cancelamento         808\n",
       "data_de_emissao                0\n",
       "protocolo                      0\n",
       "protocolo_de_cancelamento    808\n",
       "situacao                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nfe.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_nfe.to_csv(\"Raw_Data/Cleaned_DFs/df_nfe_info.csv\", encoding=\"UTF-8\", index=False)\n",
    "# df_items.to_csv(\"Raw_Data/Cleaned_DFs/df_items.csv\", encoding=\"UTF-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nota_potiguar_scrap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
